{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python388jvsc74a57bd03b229fd3c12004dab842a761dd4639bb396c3f7e567b063732ed25584d601363",
      "display_name": "Python 3.8.8 64-bit ('datascience': conda)"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "3b229fd3c12004dab842a761dd4639bb396c3f7e567b063732ed25584d601363"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APMFc3DBzZx2"
      },
      "source": [
        "# Package Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCzbE5P81Pnk"
      },
      "source": [
        "%matplotlib inline\n",
        "from code.utils import *\n",
        "from code.models import *\n",
        "\n",
        "#To ensure multiple cell output\n",
        "from IPython.core.interactiveshell import InteractiveShell  \n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlVg5b3-1MDp",
        "outputId": "ab2fba57-fe8d-4492-bbcd-1375b7c06c03"
      },
      "source": [
        "#Set to False if not using Colab\n",
        "google_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if google_colab:\n",
        "    \n",
        "    #Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    #To replicate results locally —> change project_folder\n",
        "    project_folder = Path(\"/content/drive/MyDrive/Bandit_Project/generated_data_4_project\")\n",
        "    input_file = project_folder/\"generated4.csv\"\n",
        "\n",
        "else:\n",
        "    project_folder = Path.cwd()\n",
        "    input_file = Path(\"/Users/admin/Downloads/generated4.csv\") #Change this location"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSmePRcqzc9r"
      },
      "source": [
        "# Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GL8gR9W8Rd7"
      },
      "source": [
        "#Initialize a control variable that determines whether we will import data\n",
        "reexport_var = False #Do not change if experiment results are to replicated\n",
        "hidden_include = False\n",
        "\n",
        "train_path = project_folder/\"train.csv\"\n",
        "val_path = project_folder/\"val.csv\"\n",
        "test_path = project_folder/\"test.csv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOIU2Kk51X3w"
      },
      "source": [
        "if reexport_var:\n",
        "    \n",
        "  #This CSV file is generated by running DataGeneratory.ipynb - refer notebook for additional information  \n",
        "  generate_CSV(input_file, train_path, val_path, test_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhg07ElKzfgG"
      },
      "source": [
        "# Preparing Dataset for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfGiTQQb8ibn",
        "outputId": "adca5448-30e7-447a-d750-7b8d84e26829"
      },
      "source": [
        "batch_size=1024\n",
        "n_epochs=500\n",
        "feature_columns = [\"user_id\", \"user_feature_1\", \"user_feature_2\", \"user_feature_hidden\",\n",
        "                   \"campaign_id\", \"campaign_feature_1\", \"campaign_feature_2\", \"campaign_feature_hidden\"]\n",
        "target_column = \"optimal_action\"\n",
        "\n",
        "train_dl = df_to_dataloader(train_path, feature_columns, target_column, batch_size=batch_size)\n",
        "val_dl = df_to_dataloader(val_path, feature_columns, target_column, batch_size=batch_size)\n",
        "test_dl = df_to_dataloader(test_path, feature_columns, target_column, shuffle = False, batch_size=batch_size)\n",
        "\n",
        "print(\"[INFO] Train dataloader:\")\n",
        "pprint(train_dl)\n",
        "print(\"[INFO] Val dataloader:\")\n",
        "pprint(val_dl)\n",
        "print(\"[INFO] Test dataloader:\")\n",
        "pprint(test_dl)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Train dataloader:\n<BatchDataset shapes: ({user_id: (None,), user_feature_1: (None,), user_feature_2: (None,), user_feature_hidden: (None,), campaign_id: (None,), campaign_feature_1: (None,), campaign_feature_2: (None,), campaign_feature_hidden: (None,)}, (None, 10)), types: ({user_id: tf.int64, user_feature_1: tf.float64, user_feature_2: tf.float64, user_feature_hidden: tf.float64, campaign_id: tf.int64, campaign_feature_1: tf.float64, campaign_feature_2: tf.float64, campaign_feature_hidden: tf.float64}, tf.float32)>\n[INFO] Val dataloader:\n<BatchDataset shapes: ({user_id: (None,), user_feature_1: (None,), user_feature_2: (None,), user_feature_hidden: (None,), campaign_id: (None,), campaign_feature_1: (None,), campaign_feature_2: (None,), campaign_feature_hidden: (None,)}, (None, 10)), types: ({user_id: tf.int64, user_feature_1: tf.float64, user_feature_2: tf.float64, user_feature_hidden: tf.float64, campaign_id: tf.int64, campaign_feature_1: tf.float64, campaign_feature_2: tf.float64, campaign_feature_hidden: tf.float64}, tf.float32)>\n[INFO] Test dataloader:\n<BatchDataset shapes: ({user_id: (None,), user_feature_1: (None,), user_feature_2: (None,), user_feature_hidden: (None,), campaign_id: (None,), campaign_feature_1: (None,), campaign_feature_2: (None,), campaign_feature_hidden: (None,)}, (None, 10)), types: ({user_id: tf.int64, user_feature_1: tf.float64, user_feature_2: tf.float64, user_feature_hidden: tf.float64, campaign_id: tf.int64, campaign_feature_1: tf.float64, campaign_feature_2: tf.float64, campaign_feature_hidden: tf.float64}, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxYAw5-5dgH"
      },
      "source": [
        "# Creating TF Feature Columns"
      ]
    },
    {
      "source": [
        "feature_column_dict, feature_column_input_dict = generate_feature_columns()\n",
        "\n",
        "#Defining the inputs that will be fed to each model\n",
        "inputs = {**feature_column_input_dict[\"numeric\"], **feature_column_input_dict[\"embedding\"]}"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYjRlJP68d2o"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIr5KAf7-Dc0",
        "outputId": "1b3caea0-67fa-4e0c-be40-1831af0a6bde"
      },
      "source": [
        "models_dir = project_folder/\"models\"\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "#Create the folders to save the checkpoints\n",
        "wmodel_dir = (models_dir/\"Wide\")\n",
        "dmodel_dir = (models_dir/\"Deep\")\n",
        "wdmodel_dir = (models_dir/\"W&D\")\n",
        "bayesian_dir = (models_dir/\"Bayesian\")\n",
        "\n",
        "wmodel_dir.mkdir(exist_ok=True)\n",
        "dmodel_dir.mkdir(exist_ok=True)\n",
        "wdmodel_dir.mkdir(exist_ok=True)\n",
        "bayesian_dir.mkdir(exist_ok=True)\n",
        "\n",
        "#Setting hyperparams\n",
        "lr = 1e-3\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZa01re48kRt"
      },
      "source": [
        "## Wide Only Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knfA5go2cxdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "c875182d-8509-4d45-9942-d2392e4b84f0"
      },
      "source": [
        "wmodel, wmodel_path = build_wide_model(feature_column_dict, inputs, wmodel_dir)\n",
        "wmodel.summary() #To display the architecture"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ncampaign_feature_1 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_2 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_id (InputLayer)        [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_1 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_2 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_id (InputLayer)            [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_feature_layer (DenseFeatu (None, 100000)       0           campaign_feature_1[0][0]         \n                                                                 campaign_feature_2[0][0]         \n                                                                 campaign_id[0][0]                \n                                                                 user_feature_1[0][0]             \n                                                                 user_feature_2[0][0]             \n                                                                 user_id[0][0]                    \n__________________________________________________________________________________________________\nwide_output (Dense)             (None, 10)           1000010     dense_feature_layer[0][0]        \n==================================================================================================\nTotal params: 1,000,010\nTrainable params: 1,000,010\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5ie_g9pczs2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a6315a5a-01ab-4d2f-cd03-63704e001227"
      },
      "source": [
        "\"\"\"\n",
        "#Training already done - Just load the model!\n",
        "H = wmodel.fit(train_dl, batch_size=batch_size, epochs=n_epochs, \n",
        "               validation_data=val_dl, shuffle=False, \n",
        "               validation_batch_size=batch_size, callbacks=[w_2_es, w_2_mc])\n",
        "\"\"\"               "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Training already done - Just load the model!\\nH = wmodel.fit(train_dl, batch_size=batch_size, epochs=n_epochs, \\n               validation_data=val_dl, shuffle=False, \\n               validation_batch_size=batch_size, callbacks=[w_2_es, w_2_mc])\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7tKD3qxc54q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8258e203-b52a-4b9d-ce21-58c98586abde"
      },
      "source": [
        "#The model has been trained before\n",
        "wmodel = tf.keras.models.load_model(str(wmodel_path))\n",
        "\n",
        "#Generate predictions on train, val & test set\n",
        "eval_wmodel_train = wmodel.evaluate(train_dl)\n",
        "eval_wmodel_val = wmodel.evaluate(val_dl)\n",
        "eval_wmodel_test = wmodel.evaluate(test_dl)\n",
        "\n",
        "#Print the results\n",
        "print(\"\\n[INFO] On Training Set:\")\n",
        "print(eval_wmodel_train)\n",
        "print(\"\\n[INFO] On Validation Set:\")\n",
        "print(eval_wmodel_val)\n",
        "print(\"\\n[INFO] On Test Set:\")\n",
        "print(eval_wmodel_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/admin/miniforge3/envs/datascience/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['user_feature_hidden', 'campaign_feature_hidden'] which did not match any model input. They will be ignored by the model.\n",
            "  warnings.warn(\n",
            "5860/5860 [==============================] - 664s 111ms/step - loss: 1.6183 - accuracy: 0.3534 - auc_1: 0.8420\n",
            "1954/1954 [==============================] - 817s 416ms/step - loss: 1.6897 - accuracy: 0.3331 - auc_1: 0.8280\n",
            "1954/1954 [==============================] - 849s 435ms/step - loss: 1.6896 - accuracy: 0.3335 - auc_1: 0.8280\n",
            "\n",
            "[INFO] On Training Set:\n",
            "[1.6183046102523804, 0.35337594151496887, 0.8419806957244873]\n",
            "\n",
            "[INFO] On Validation Set:\n",
            "[1.6896576881408691, 0.33308184146881104, 0.8280330896377563]\n",
            "\n",
            "[INFO] On Test Set:\n",
            "[1.6896229982376099, 0.3335239887237549, 0.8280342221260071]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H6t6jvnWeVy"
      },
      "source": [
        "## Deep Only Model\n",
        "\n",
        "These are 4 different Deep-only model architectures that we use, namely:\n",
        "\n",
        "1. With only embeddings\n",
        "2. With only numeric features\n",
        "3. With embeddings & numeric features\n",
        "4. With both normal & hidden numeric features\n",
        "\n",
        "For the sake of comparison, we employ the same `[512, 256, 128]` architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ncampaign_feature_1 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_2 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_id (InputLayer)        [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_1 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_2 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_id (InputLayer)            [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_feature_layer (DenseFeatu (None, 23)           16700       campaign_feature_1[0][0]         \n                                                                 campaign_feature_2[0][0]         \n                                                                 campaign_id[0][0]                \n                                                                 user_feature_1[0][0]             \n                                                                 user_feature_2[0][0]             \n                                                                 user_id[0][0]                    \n__________________________________________________________________________________________________\nfc_1 (Dense)                    (None, 512)          12288       dense_feature_layer[0][0]        \n__________________________________________________________________________________________________\nfc_2 (Dense)                    (None, 256)          131328      fc_1[0][0]                       \n__________________________________________________________________________________________________\nfc_3 (Dense)                    (None, 128)          32896       fc_2[0][0]                       \n__________________________________________________________________________________________________\ndeep_output (Dense)             (None, 10)           1290        fc_3[0][0]                       \n==================================================================================================\nTotal params: 194,502\nTrainable params: 194,502\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model 1: Only Embeddings\n",
        "dmodel_1_emb, dmodel_1_emb_path = build_deep_model(feature_column_dict[\"embedding\"], inputs, dmodel_dir, \n",
        "                                                name=\"dmodel_1_emb.h5\", ckpt_name=\"dmodel_1_emb_checkpoint.h5\")\n",
        "\n",
        "#Display summary to just show the results\n",
        "dmodel_1_emb.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ncampaign_feature_1 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_2 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_id (InputLayer)        [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_1 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_2 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_id (InputLayer)            [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_feature_layer (DenseFeatu (None, 4)            0           campaign_feature_1[0][0]         \n                                                                 campaign_feature_2[0][0]         \n                                                                 campaign_id[0][0]                \n                                                                 user_feature_1[0][0]             \n                                                                 user_feature_2[0][0]             \n                                                                 user_id[0][0]                    \n__________________________________________________________________________________________________\nfc_1 (Dense)                    (None, 512)          2560        dense_feature_layer[0][0]        \n__________________________________________________________________________________________________\nfc_2 (Dense)                    (None, 256)          131328      fc_1[0][0]                       \n__________________________________________________________________________________________________\nfc_3 (Dense)                    (None, 128)          32896       fc_2[0][0]                       \n__________________________________________________________________________________________________\ndeep_output (Dense)             (None, 10)           1290        fc_3[0][0]                       \n==================================================================================================\nTotal params: 168,074\nTrainable params: 168,074\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model 2: With only numeric features\n",
        "dmodel_2_num, dmodel_2_num_path = build_deep_model(feature_column_dict[\"numeric\"], inputs, dmodel_dir, \n",
        "                                                name=\"dmodel_2_num.h5\", ckpt_name=\"dmodel_2_num_checkpoint.h5\")\n",
        "dmodel_2_num.summary()                                                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ncampaign_feature_1 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_2 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_id (InputLayer)        [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_1 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_2 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_id (InputLayer)            [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_feature_layer (DenseFeatu (None, 100027)       16700       campaign_feature_1[0][0]         \n                                                                 campaign_feature_2[0][0]         \n                                                                 campaign_id[0][0]                \n                                                                 user_feature_1[0][0]             \n                                                                 user_feature_2[0][0]             \n                                                                 user_id[0][0]                    \n__________________________________________________________________________________________________\nfc_1 (Dense)                    (None, 512)          51214336    dense_feature_layer[0][0]        \n__________________________________________________________________________________________________\nfc_2 (Dense)                    (None, 256)          131328      fc_1[0][0]                       \n__________________________________________________________________________________________________\nfc_3 (Dense)                    (None, 128)          32896       fc_2[0][0]                       \n__________________________________________________________________________________________________\ndeep_output (Dense)             (None, 10)           1290        fc_3[0][0]                       \n==================================================================================================\nTotal params: 51,396,550\nTrainable params: 51,396,550\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model 3: With embeddings and numeric features\n",
        "dmodel_3_num_emb, dmodel_3_num_emb_path = build_deep_model(feature_column_dict, inputs, dmodel_dir, \n",
        "                                                name=\"dmodel_3_num_emb.h5\", ckpt_name=\"dmodel_3_num_emb_checkpoint.h5\")\n",
        "dmodel_3_num_emb.summary()                                                "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVQtiRG6N2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91ac518-dc10-4dbc-ba0c-ccbc83c85c6a"
      },
      "source": [
        "#Model 4: With normal & hidden numeric features\n",
        "#Get the new feature column & input dicts\n",
        "feature_column_dict_hidden, feature_column_input_dict_hidden = generate_feature_columns(hidden_include=True)\n",
        "inputs_hidden = {**feature_column_input_dict_hidden[\"numeric\"], **feature_column_input_dict_hidden[\"embedding\"]}\n",
        "dmodel_4_hid, dmodel_4_hid_path = build_deep_model(feature_column_dict_hidden, inputs_hidden, dmodel_dir, \n",
        "                                                    name=\"dmodel_4_hid.h5\", ckpt_name=\"dmodel_4_hid_checkpoint.h5\")\n",
        "dmodel_4_hid.summary()                            "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ncampaign_feature_1 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_2 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_hidden (InputL [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_id (InputLayer)        [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_1 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_2 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_hidden (InputLayer [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_id (InputLayer)            [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_feature_layer (DenseFeatu (None, 100029)       16700       campaign_feature_1[0][0]         \n                                                                 campaign_feature_2[0][0]         \n                                                                 campaign_feature_hidden[0][0]    \n                                                                 campaign_id[0][0]                \n                                                                 user_feature_1[0][0]             \n                                                                 user_feature_2[0][0]             \n                                                                 user_feature_hidden[0][0]        \n                                                                 user_id[0][0]                    \n__________________________________________________________________________________________________\nfc_1 (Dense)                    (None, 512)          51215360    dense_feature_layer[0][0]        \n__________________________________________________________________________________________________\nfc_2 (Dense)                    (None, 256)          131328      fc_1[0][0]                       \n__________________________________________________________________________________________________\nfc_3 (Dense)                    (None, 128)          32896       fc_2[0][0]                       \n__________________________________________________________________________________________________\ndeep_output (Dense)             (None, 10)           1290        fc_3[0][0]                       \n==================================================================================================\nTotal params: 51,397,574\nTrainable params: 51,397,574\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUuGMh9JZYQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5f6e9b-f301-4355-f4bc-f696afd8c622"
      },
      "source": [
        "\"\"\"\n",
        "#Training already done —> just load the models and evaluate!\n",
        "H = dmodel_1_emb.fit(train_dl, batch_size=batch_size, epochs=n_epochs, \n",
        "               validation_data=val_dl, shuffle=False, \n",
        "               validation_batch_size=batch_size, callbacks=[d_es, d_mc])\n",
        "\"\"\"               \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['user_feature_hidden', 'campaign_feature_hidden'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2930/2930 [==============================] - 114s 35ms/step - loss: 0.8908 - accuracy: 0.6365 - auc: 0.9479 - val_loss: 0.5381 - val_accuracy: 0.7764 - val_auc: 0.9820\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.77640, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 2/500\n",
            "2930/2930 [==============================] - 113s 35ms/step - loss: 0.5255 - accuracy: 0.7786 - auc: 0.9827 - val_loss: 0.5052 - val_accuracy: 0.7836 - val_auc: 0.9839\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.77640 to 0.78357, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 3/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.5000 - accuracy: 0.7859 - auc: 0.9843 - val_loss: 0.4882 - val_accuracy: 0.7905 - val_auc: 0.9851\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.78357 to 0.79049, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 4/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4854 - accuracy: 0.7906 - auc: 0.9852 - val_loss: 0.4850 - val_accuracy: 0.7902 - val_auc: 0.9852\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.79049\n",
            "Epoch 5/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.4773 - accuracy: 0.7932 - auc: 0.9857 - val_loss: 0.4757 - val_accuracy: 0.7927 - val_auc: 0.9858\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.79049 to 0.79273, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 6/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.4708 - accuracy: 0.7954 - auc: 0.9860 - val_loss: 0.4690 - val_accuracy: 0.7960 - val_auc: 0.9861\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.79273 to 0.79595, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 7/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.4652 - accuracy: 0.7975 - auc: 0.9864 - val_loss: 0.4688 - val_accuracy: 0.7953 - val_auc: 0.9861\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.79595\n",
            "Epoch 8/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4610 - accuracy: 0.7989 - auc: 0.9866 - val_loss: 0.4649 - val_accuracy: 0.7966 - val_auc: 0.9863\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.79595 to 0.79664, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 9/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4580 - accuracy: 0.7998 - auc: 0.9868 - val_loss: 0.4671 - val_accuracy: 0.7951 - val_auc: 0.9862\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.79664\n",
            "Epoch 10/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4552 - accuracy: 0.8010 - auc: 0.9869 - val_loss: 0.4598 - val_accuracy: 0.7983 - val_auc: 0.9866\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.79664 to 0.79826, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 11/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4521 - accuracy: 0.8022 - auc: 0.9871 - val_loss: 0.4552 - val_accuracy: 0.8007 - val_auc: 0.9869\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.79826 to 0.80070, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 12/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4499 - accuracy: 0.8029 - auc: 0.9872 - val_loss: 0.4578 - val_accuracy: 0.7994 - val_auc: 0.9867\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.80070\n",
            "Epoch 13/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4481 - accuracy: 0.8037 - auc: 0.9873 - val_loss: 0.4502 - val_accuracy: 0.8029 - val_auc: 0.9871\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.80070 to 0.80289, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 14/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4459 - accuracy: 0.8046 - auc: 0.9874 - val_loss: 0.4609 - val_accuracy: 0.7975 - val_auc: 0.9865\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.80289\n",
            "Epoch 15/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4443 - accuracy: 0.8050 - auc: 0.9875 - val_loss: 0.4535 - val_accuracy: 0.8012 - val_auc: 0.9869\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.80289\n",
            "Epoch 16/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4433 - accuracy: 0.8057 - auc: 0.9876 - val_loss: 0.4472 - val_accuracy: 0.8043 - val_auc: 0.9873\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.80289 to 0.80434, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 17/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4416 - accuracy: 0.8062 - auc: 0.9876 - val_loss: 0.4438 - val_accuracy: 0.8057 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.80434 to 0.80570, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 18/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4406 - accuracy: 0.8065 - auc: 0.9877 - val_loss: 0.4446 - val_accuracy: 0.8044 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80570\n",
            "Epoch 19/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4390 - accuracy: 0.8074 - auc: 0.9878 - val_loss: 0.4449 - val_accuracy: 0.8047 - val_auc: 0.9874\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.80570\n",
            "Epoch 20/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4378 - accuracy: 0.8076 - auc: 0.9879 - val_loss: 0.4472 - val_accuracy: 0.8032 - val_auc: 0.9873\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.80570\n",
            "Epoch 21/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4365 - accuracy: 0.8083 - auc: 0.9879 - val_loss: 0.4447 - val_accuracy: 0.8044 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.80570\n",
            "Epoch 22/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4355 - accuracy: 0.8089 - auc: 0.9880 - val_loss: 0.4447 - val_accuracy: 0.8044 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.80570\n",
            "Epoch 23/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4340 - accuracy: 0.8090 - auc: 0.9881 - val_loss: 0.4422 - val_accuracy: 0.8059 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.80570 to 0.80587, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 24/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4337 - accuracy: 0.8093 - auc: 0.9881 - val_loss: 0.4401 - val_accuracy: 0.8068 - val_auc: 0.9876\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.80587 to 0.80680, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 25/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4329 - accuracy: 0.8099 - auc: 0.9881 - val_loss: 0.4441 - val_accuracy: 0.8045 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.80680\n",
            "Epoch 26/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4320 - accuracy: 0.8102 - auc: 0.9881 - val_loss: 0.4415 - val_accuracy: 0.8057 - val_auc: 0.9876\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.80680\n",
            "Epoch 27/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4317 - accuracy: 0.8103 - auc: 0.9882 - val_loss: 0.4403 - val_accuracy: 0.8060 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.80680\n",
            "Epoch 28/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4306 - accuracy: 0.8106 - auc: 0.9882 - val_loss: 0.4420 - val_accuracy: 0.8052 - val_auc: 0.9875\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.80680\n",
            "Epoch 29/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4297 - accuracy: 0.8110 - auc: 0.9883 - val_loss: 0.4396 - val_accuracy: 0.8064 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.80680\n",
            "Epoch 30/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4298 - accuracy: 0.8109 - auc: 0.9883 - val_loss: 0.4372 - val_accuracy: 0.8074 - val_auc: 0.9878\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.80680 to 0.80744, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 31/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4289 - accuracy: 0.8114 - auc: 0.9883 - val_loss: 0.4364 - val_accuracy: 0.8086 - val_auc: 0.9878\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.80744 to 0.80860, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 32/500\n",
            "2930/2930 [==============================] - 109s 35ms/step - loss: 0.4275 - accuracy: 0.8120 - auc: 0.9884 - val_loss: 0.4395 - val_accuracy: 0.8067 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.80860\n",
            "Epoch 33/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4276 - accuracy: 0.8119 - auc: 0.9884 - val_loss: 0.4343 - val_accuracy: 0.8088 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.80860 to 0.80880, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 34/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4269 - accuracy: 0.8121 - auc: 0.9884 - val_loss: 0.4366 - val_accuracy: 0.8075 - val_auc: 0.9878\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.80880\n",
            "Epoch 35/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4255 - accuracy: 0.8127 - auc: 0.9885 - val_loss: 0.4383 - val_accuracy: 0.8076 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.80880\n",
            "Epoch 36/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4255 - accuracy: 0.8128 - auc: 0.9885 - val_loss: 0.4386 - val_accuracy: 0.8072 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.80880\n",
            "Epoch 37/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4248 - accuracy: 0.8130 - auc: 0.9885 - val_loss: 0.4364 - val_accuracy: 0.8076 - val_auc: 0.9878\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.80880\n",
            "Epoch 38/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4245 - accuracy: 0.8133 - auc: 0.9885 - val_loss: 0.4352 - val_accuracy: 0.8083 - val_auc: 0.9879\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.80880\n",
            "Epoch 39/500\n",
            "2930/2930 [==============================] - 109s 34ms/step - loss: 0.4239 - accuracy: 0.8133 - auc: 0.9886 - val_loss: 0.4405 - val_accuracy: 0.8057 - val_auc: 0.9876\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.80880\n",
            "Epoch 40/500\n",
            "2930/2930 [==============================] - 109s 35ms/step - loss: 0.4236 - accuracy: 0.8133 - auc: 0.9886 - val_loss: 0.4380 - val_accuracy: 0.8072 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.80880\n",
            "Epoch 41/500\n",
            "2930/2930 [==============================] - 109s 35ms/step - loss: 0.4232 - accuracy: 0.8135 - auc: 0.9886 - val_loss: 0.4349 - val_accuracy: 0.8085 - val_auc: 0.9879\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.80880\n",
            "Epoch 42/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4223 - accuracy: 0.8140 - auc: 0.9886 - val_loss: 0.4341 - val_accuracy: 0.8088 - val_auc: 0.9879\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.80880 to 0.80882, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 43/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4222 - accuracy: 0.8140 - auc: 0.9887 - val_loss: 0.4331 - val_accuracy: 0.8092 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.80882 to 0.80919, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 44/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4215 - accuracy: 0.8146 - auc: 0.9887 - val_loss: 0.4379 - val_accuracy: 0.8074 - val_auc: 0.9877\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.80919\n",
            "Epoch 45/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4215 - accuracy: 0.8144 - auc: 0.9887 - val_loss: 0.4330 - val_accuracy: 0.8089 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.80919\n",
            "Epoch 46/500\n",
            "2930/2930 [==============================] - 109s 35ms/step - loss: 0.4212 - accuracy: 0.8140 - auc: 0.9887 - val_loss: 0.4306 - val_accuracy: 0.8104 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.80919 to 0.81035, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 47/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4202 - accuracy: 0.8149 - auc: 0.9887 - val_loss: 0.4324 - val_accuracy: 0.8090 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.81035\n",
            "Epoch 48/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4202 - accuracy: 0.8148 - auc: 0.9887 - val_loss: 0.4326 - val_accuracy: 0.8092 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.81035\n",
            "Epoch 49/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4197 - accuracy: 0.8150 - auc: 0.9888 - val_loss: 0.4304 - val_accuracy: 0.8101 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.81035\n",
            "Epoch 50/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.4201 - accuracy: 0.8149 - auc: 0.9888 - val_loss: 0.4373 - val_accuracy: 0.8070 - val_auc: 0.9878\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.81035\n",
            "Epoch 51/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4189 - accuracy: 0.8153 - auc: 0.9888 - val_loss: 0.4331 - val_accuracy: 0.8094 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.81035\n",
            "Epoch 52/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4188 - accuracy: 0.8153 - auc: 0.9888 - val_loss: 0.4339 - val_accuracy: 0.8087 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.81035\n",
            "Epoch 53/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4186 - accuracy: 0.8155 - auc: 0.9888 - val_loss: 0.4306 - val_accuracy: 0.8099 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.81035\n",
            "Epoch 54/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4178 - accuracy: 0.8159 - auc: 0.9889 - val_loss: 0.4311 - val_accuracy: 0.8101 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.81035\n",
            "Epoch 55/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4176 - accuracy: 0.8159 - auc: 0.9889 - val_loss: 0.4303 - val_accuracy: 0.8106 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00055: val_accuracy improved from 0.81035 to 0.81058, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 56/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4174 - accuracy: 0.8161 - auc: 0.9889 - val_loss: 0.4316 - val_accuracy: 0.8099 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.81058\n",
            "Epoch 57/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4176 - accuracy: 0.8158 - auc: 0.9889 - val_loss: 0.4318 - val_accuracy: 0.8099 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.81058\n",
            "Epoch 58/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4170 - accuracy: 0.8163 - auc: 0.9889 - val_loss: 0.4312 - val_accuracy: 0.8103 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.81058\n",
            "Epoch 59/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4165 - accuracy: 0.8164 - auc: 0.9889 - val_loss: 0.4308 - val_accuracy: 0.8100 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.81058\n",
            "Epoch 60/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4164 - accuracy: 0.8163 - auc: 0.9889 - val_loss: 0.4320 - val_accuracy: 0.8098 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.81058\n",
            "Epoch 61/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4168 - accuracy: 0.8164 - auc: 0.9889 - val_loss: 0.4323 - val_accuracy: 0.8091 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.81058\n",
            "Epoch 62/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4160 - accuracy: 0.8167 - auc: 0.9890 - val_loss: 0.4336 - val_accuracy: 0.8091 - val_auc: 0.9879\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.81058\n",
            "Epoch 63/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4159 - accuracy: 0.8167 - auc: 0.9890 - val_loss: 0.4305 - val_accuracy: 0.8106 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00063: val_accuracy improved from 0.81058 to 0.81065, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 64/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4155 - accuracy: 0.8169 - auc: 0.9890 - val_loss: 0.4337 - val_accuracy: 0.8089 - val_auc: 0.9879\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.81065\n",
            "Epoch 65/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4156 - accuracy: 0.8166 - auc: 0.9890 - val_loss: 0.4309 - val_accuracy: 0.8102 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.81065\n",
            "Epoch 66/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4153 - accuracy: 0.8168 - auc: 0.9890 - val_loss: 0.4337 - val_accuracy: 0.8087 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.81065\n",
            "Epoch 67/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4150 - accuracy: 0.8170 - auc: 0.9890 - val_loss: 0.4324 - val_accuracy: 0.8096 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.81065\n",
            "Epoch 68/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4147 - accuracy: 0.8171 - auc: 0.9890 - val_loss: 0.4325 - val_accuracy: 0.8097 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.81065\n",
            "Epoch 69/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4137 - accuracy: 0.8175 - auc: 0.9891 - val_loss: 0.4301 - val_accuracy: 0.8106 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.81065\n",
            "Epoch 70/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4142 - accuracy: 0.8172 - auc: 0.9891 - val_loss: 0.4291 - val_accuracy: 0.8111 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00070: val_accuracy improved from 0.81065 to 0.81106, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 71/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4139 - accuracy: 0.8175 - auc: 0.9891 - val_loss: 0.4299 - val_accuracy: 0.8105 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.81106\n",
            "Epoch 72/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4137 - accuracy: 0.8177 - auc: 0.9891 - val_loss: 0.4315 - val_accuracy: 0.8096 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.81106\n",
            "Epoch 73/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.4135 - accuracy: 0.8177 - auc: 0.9891 - val_loss: 0.4309 - val_accuracy: 0.8102 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.81106\n",
            "Epoch 74/500\n",
            "2930/2930 [==============================] - 112s 35ms/step - loss: 0.4132 - accuracy: 0.8180 - auc: 0.9891 - val_loss: 0.4313 - val_accuracy: 0.8101 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.81106\n",
            "Epoch 75/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4132 - accuracy: 0.8179 - auc: 0.9891 - val_loss: 0.4302 - val_accuracy: 0.8104 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.81106\n",
            "Epoch 76/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4130 - accuracy: 0.8177 - auc: 0.9891 - val_loss: 0.4319 - val_accuracy: 0.8101 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.81106\n",
            "Epoch 77/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4128 - accuracy: 0.8178 - auc: 0.9891 - val_loss: 0.4278 - val_accuracy: 0.8116 - val_auc: 0.9883\n",
            "\n",
            "Epoch 00077: val_accuracy improved from 0.81106 to 0.81163, saving model to /content/drive/MyDrive/Bandit_Project/generated_data_4_project/models/Deep/dmodel_checkpoint_seq.h5\n",
            "Epoch 78/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4124 - accuracy: 0.8181 - auc: 0.9891 - val_loss: 0.4294 - val_accuracy: 0.8110 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.81163\n",
            "Epoch 79/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4121 - accuracy: 0.8181 - auc: 0.9892 - val_loss: 0.4291 - val_accuracy: 0.8109 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.81163\n",
            "Epoch 80/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4122 - accuracy: 0.8182 - auc: 0.9892 - val_loss: 0.4299 - val_accuracy: 0.8106 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.81163\n",
            "Epoch 81/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4122 - accuracy: 0.8181 - auc: 0.9892 - val_loss: 0.4300 - val_accuracy: 0.8107 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.81163\n",
            "Epoch 82/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4120 - accuracy: 0.8182 - auc: 0.9892 - val_loss: 0.4322 - val_accuracy: 0.8092 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.81163\n",
            "Epoch 83/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4119 - accuracy: 0.8182 - auc: 0.9892 - val_loss: 0.4294 - val_accuracy: 0.8108 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.81163\n",
            "Epoch 84/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4112 - accuracy: 0.8186 - auc: 0.9892 - val_loss: 0.4292 - val_accuracy: 0.8107 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.81163\n",
            "Epoch 85/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4113 - accuracy: 0.8186 - auc: 0.9892 - val_loss: 0.4329 - val_accuracy: 0.8086 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.81163\n",
            "Epoch 86/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4108 - accuracy: 0.8187 - auc: 0.9892 - val_loss: 0.4285 - val_accuracy: 0.8113 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.81163\n",
            "Epoch 87/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4110 - accuracy: 0.8186 - auc: 0.9892 - val_loss: 0.4295 - val_accuracy: 0.8107 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.81163\n",
            "Epoch 88/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4107 - accuracy: 0.8188 - auc: 0.9892 - val_loss: 0.4289 - val_accuracy: 0.8111 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.81163\n",
            "Epoch 89/500\n",
            "2930/2930 [==============================] - 109s 35ms/step - loss: 0.4103 - accuracy: 0.8189 - auc: 0.9892 - val_loss: 0.4324 - val_accuracy: 0.8096 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.81163\n",
            "Epoch 90/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4105 - accuracy: 0.8188 - auc: 0.9892 - val_loss: 0.4301 - val_accuracy: 0.8108 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.81163\n",
            "Epoch 91/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4104 - accuracy: 0.8189 - auc: 0.9892 - val_loss: 0.4307 - val_accuracy: 0.8107 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.81163\n",
            "Epoch 92/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4103 - accuracy: 0.8189 - auc: 0.9893 - val_loss: 0.4294 - val_accuracy: 0.8108 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.81163\n",
            "Epoch 93/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4100 - accuracy: 0.8192 - auc: 0.9893 - val_loss: 0.4300 - val_accuracy: 0.8103 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.81163\n",
            "Epoch 94/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4100 - accuracy: 0.8191 - auc: 0.9893 - val_loss: 0.4300 - val_accuracy: 0.8106 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.81163\n",
            "Epoch 95/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4097 - accuracy: 0.8190 - auc: 0.9893 - val_loss: 0.4306 - val_accuracy: 0.8106 - val_auc: 0.9880\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.81163\n",
            "Epoch 96/500\n",
            "2930/2930 [==============================] - 110s 35ms/step - loss: 0.4096 - accuracy: 0.8193 - auc: 0.9893 - val_loss: 0.4291 - val_accuracy: 0.8109 - val_auc: 0.9882\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.81163\n",
            "Epoch 97/500\n",
            "2930/2930 [==============================] - 111s 35ms/step - loss: 0.4095 - accuracy: 0.8193 - auc: 0.9893 - val_loss: 0.4298 - val_accuracy: 0.8107 - val_auc: 0.9881\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.81163\n",
            "Epoch 00097: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uESh9vMfheC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1444e7fc-6854-4146-f89c-2785c9791988"
      },
      "source": [
        "#For Deep Model 1: With Only Embeddings\n",
        "dmodel_1_emb = tf.keras.models.load_model(str(dmodel_1_emb_path))\n",
        "\n",
        "#Generate predictions on train, val & test set\n",
        "eval_dmodel_1_emb_train = dmodel_1_emb.evaluate(train_dl, batch_size=batch_size)\n",
        "eval_dmodel_1_emb_val = dmodel_1_emb.evaluate(val_dl, batch_size=batch_size)\n",
        "eval_dmodel_1_emb_test = dmodel_1_emb.evaluate(test_dl, batch_size=batch_size)\n",
        "\n",
        "#Print the results\n",
        "print(\"\\n[INFO] On Training Set:\")\n",
        "print(eval_dmodel_1_emb_train)\n",
        "print(\"\\n[INFO] On Validation Set:\")\n",
        "print(eval_dmodel_1_emb_val)\n",
        "print(\"\\n[INFO] On Test Set:\")\n",
        "print(eval_dmodel_1_emb_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/admin/miniforge3/envs/datascience/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['user_feature_hidden', 'campaign_feature_hidden'] which did not match any model input. They will be ignored by the model.\n",
            "  warnings.warn(\n",
            "5860/5860 [==============================] - 129s 20ms/step - loss: 1.8425 - accuracy: 0.2775 - auc_3: 0.7829\n",
            "1954/1954 [==============================] - 42s 19ms/step - loss: 1.8593 - accuracy: 0.2704 - auc_3: 0.7780\n",
            "1954/1954 [==============================] - 36s 19ms/step - loss: 1.8599 - accuracy: 0.2700 - auc_3: 0.7778\n",
            "\n",
            "[INFO] On Training Set:\n",
            "[1.842515468597412, 0.27750545740127563, 0.7828748822212219]\n",
            "\n",
            "[INFO] On Validation Set:\n",
            "[1.8593494892120361, 0.270426869392395, 0.7780262231826782]\n",
            "\n",
            "[INFO] On Test Set:\n",
            "[1.8598766326904297, 0.27002349495887756, 0.7778425216674805]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5860/5860 [==============================] - 132s 20ms/step - loss: 0.7121 - accuracy: 0.6786 - auc_2: 0.9691\n",
            "1954/1954 [==============================] - 43s 19ms/step - loss: 0.7128 - accuracy: 0.6782 - auc_2: 0.9690\n",
            "1954/1954 [==============================] - 35s 18ms/step - loss: 0.7128 - accuracy: 0.6781 - auc_2: 0.9690\n",
            "\n",
            "[INFO] On Training Set:\n",
            "[0.7120957374572754, 0.6786260604858398, 0.9690925478935242]\n",
            "\n",
            "[INFO] On Validation Set:\n",
            "[0.7128351330757141, 0.6781636476516724, 0.9690285325050354]\n",
            "\n",
            "[INFO] On Test Set:\n",
            "[0.712820827960968, 0.6781215071678162, 0.9690293073654175]\n"
          ]
        }
      ],
      "source": [
        "#For Deep Model 2: With Only Numeric Features\n",
        "dmodel_2_num = tf.keras.models.load_model(str(dmodel_2_num_path))\n",
        "\n",
        "#Generate predictions on train, val & test set\n",
        "eval_dmodel_2_num_train = dmodel_2_num.evaluate(train_dl, batch_size=batch_size)\n",
        "eval_dmodel_2_num_val = dmodel_2_num.evaluate(val_dl, batch_size=batch_size)\n",
        "eval_dmodel_2_num_test = dmodel_2_num.evaluate(test_dl, batch_size=batch_size)\n",
        "\n",
        "#Print the results\n",
        "print(\"\\n[INFO] On Training Set:\")\n",
        "print(eval_dmodel_2_num_train)\n",
        "print(\"\\n[INFO] On Validation Set:\")\n",
        "print(eval_dmodel_2_num_val)\n",
        "print(\"\\n[INFO] On Test Set:\")\n",
        "print(eval_dmodel_2_num_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/admin/miniforge3/envs/datascience/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['user_feature_hidden', 'campaign_feature_hidden'] which did not match any model input. They will be ignored by the model.\n",
            "  warnings.warn(\n",
            "5860/5860 [==============================] - 133s 20ms/step - loss: 0.4230 - accuracy: 0.8144 - auc_3: 0.9886\n",
            "1954/1954 [==============================] - 42s 19ms/step - loss: 0.4344 - accuracy: 0.8090 - auc_3: 0.9880\n",
            "1954/1954 [==============================] - 34s 17ms/step - loss: 0.4340 - accuracy: 0.8097 - auc_3: 0.9880\n",
            "\n",
            "[INFO] On Training Set:\n",
            "[0.4229627549648285, 0.8143868446350098, 0.9886314868927002]\n",
            "\n",
            "[INFO] On Validation Set:\n",
            "[0.4344482421875, 0.8090035915374756, 0.9879717826843262]\n",
            "\n",
            "[INFO] On Test Set:\n",
            "[0.433987021446228, 0.8096619844436646, 0.9879959225654602]\n"
          ]
        }
      ],
      "source": [
        "#For Deep Model 3: With Embeddings + Numeric Features\n",
        "dmodel_3_num_emb = tf.keras.models.load_model(str(dmodel_3_num_emb_path))\n",
        "\n",
        "#Generate predictions on train, val & test set\n",
        "eval_dmodel_3_num_emb_train = dmodel_3_num_emb.evaluate(train_dl, batch_size=batch_size)\n",
        "eval_dmodel_3_num_emb_val = dmodel_3_num_emb.evaluate(val_dl, batch_size=batch_size)\n",
        "eval_dmodel_3_num_emb_test = dmodel_3_num_emb.evaluate(test_dl, batch_size=batch_size)\n",
        "\n",
        "#Print the results\n",
        "print(\"\\n[INFO] On Training Set:\")\n",
        "print(eval_dmodel_3_num_emb_train)\n",
        "print(\"\\n[INFO] On Validation Set:\")\n",
        "print(eval_dmodel_3_num_emb_val)\n",
        "print(\"\\n[INFO] On Test Set:\")\n",
        "print(eval_dmodel_3_num_emb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5860/5860 [==============================] - 134s 21ms/step - loss: 0.0452 - accuracy: 0.9811 - auc_2: 0.9999\n",
            "1954/1954 [==============================] - 44s 20ms/step - loss: 0.0460 - accuracy: 0.9807 - auc_2: 0.9999\n",
            "1954/1954 [==============================] - 35s 18ms/step - loss: 0.0460 - accuracy: 0.9807 - auc_2: 0.9999\n",
            "\n",
            "[INFO] On Training Set:\n",
            "[0.045185163617134094, 0.9811403155326843, 0.9998613595962524]\n",
            "\n",
            "[INFO] On Validation Set:\n",
            "[0.04604894295334816, 0.9806995391845703, 0.9998517632484436]\n",
            "\n",
            "[INFO] On Test Set:\n",
            "[0.046024858951568604, 0.9807425141334534, 0.9998557567596436]\n"
          ]
        }
      ],
      "source": [
        "#For Deep Model 4: With Both Hidden & Observable Numeric Features\n",
        "dmodel_4_hid = tf.keras.models.load_model(str(dmodel_4_hid_path))\n",
        "\n",
        "#Generate predictions on train, val & test set\n",
        "eval_dmodel_4_hid_train = dmodel_4_hid.evaluate(train_dl, batch_size=batch_size)\n",
        "eval_dmodel_4_hid_val = dmodel_4_hid.evaluate(val_dl, batch_size=batch_size)\n",
        "eval_dmodel_4_hid_test = dmodel_4_hid.evaluate(test_dl, batch_size=batch_size)\n",
        "\n",
        "#Print the results\n",
        "print(\"\\n[INFO] On Training Set:\")\n",
        "print(eval_dmodel_4_hid_train)\n",
        "print(\"\\n[INFO] On Validation Set:\")\n",
        "print(eval_dmodel_4_hid_val)\n",
        "print(\"\\n[INFO] On Test Set:\")\n",
        "print(eval_dmodel_4_hid_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peeUrdzMWmUA"
      },
      "source": [
        "## Wide & Deep Model\n",
        "\n",
        "Wide part receives the crossed columns.\n",
        "Deep part receives the numeric features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ncampaign_feature_1 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_feature_2 (InputLayer) [(None,)]            0                                            \n__________________________________________________________________________________________________\ncampaign_id (InputLayer)        [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_1 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_feature_2 (InputLayer)     [(None,)]            0                                            \n__________________________________________________________________________________________________\nuser_id (InputLayer)            [(None,)]            0                                            \n__________________________________________________________________________________________________\ndense_feature_layer (DenseFeatu (None, 100000)       0           campaign_feature_1[0][0]         \n                                                                 campaign_feature_2[0][0]         \n                                                                 campaign_id[0][0]                \n                                                                 user_feature_1[0][0]             \n                                                                 user_feature_2[0][0]             \n                                                                 user_id[0][0]                    \n__________________________________________________________________________________________________\nwide_output (Dense)             (None, 10)           1000010     dense_feature_layer[0][0]        \n==================================================================================================\nTotal params: 1,000,010\nTrainable params: 1,000,010\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "wdmodel, wdmodel_path = build_wide_model(feature_column_dict, inputs, wmodel_dir)\n",
        "wdmodel.summary() #To display the architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "#Model is already trained - load the model directly\n",
        "wdmodel = tf.keras.models.load_model(str(wdmodel_checkpoint_path))\n",
        "H = wdmodel.fit(train_dl, batch_size=batch_size, epochs=n_epochs, \n",
        "               validation_data=val_dl, shuffle=False, \n",
        "               validation_batch_size=batch_size, callbacks=[wd_es, wd_mc])\n",
        "\"\"\"               "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/admin/miniforge3/envs/datascience/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['user_feature_hidden', 'campaign_feature_hidden'] which did not match any model input. They will be ignored by the model.\n",
            "  warnings.warn(\n",
            "4400/5860 [=====================>........] - ETA: 3:01 - loss: 1.6181 - accuracy: 0.3535 - auc_1: 0.8420"
          ]
        }
      ],
      "source": [
        "#The model has been trained before\n",
        "wdmodel = tf.keras.models.load_model(str(wdmodel_path))\n",
        "\n",
        "#Generate predictions on train, val & test set\n",
        "eval_wdmodel_train = wdmodel.evaluate(train_dl, batch_size=batch_size)\n",
        "eval_wdmodel_val = wdmodel.evaluate(val_dl, batch_size=batch_size)\n",
        "eval_wdmodel_test = wdmodel.evaluate(test_dl, batch_size=batch_size)\n",
        "\n",
        "#Print the results\n",
        "print(\"\\n[INFO] On Training Set:\")\n",
        "print(eval_wdmodel_train)\n",
        "print(\"\\n[INFO] On Validation Set:\")\n",
        "print(eval_wdmodel_val)\n",
        "print(\"\\n[INFO] On Test Set:\")\n",
        "print(eval_wdmodel_test)"
      ]
    },
    {
      "source": [
        "# Summary of Results\n",
        "\n",
        "This section reproduces Table 1 of the paper _Comparing the Performance of Deep and Wide vs. Deep Only Neural Networks_ from the results derived from the previous sections for the different model types and architectures. We use the `tabulate` package to print the table format."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l = [[\"Random\", \"none\", \"none\", 10.0, 10.0, 10.0],\n",
        "     [\"Wide\", \"none\", \"user_id X campaign_id\", f\"{eval_wmodel_train[1]:.2f}\", f\"{eval_wmodel_val[1]:.2f}\", f\"{eval_wmodel_test[1]:.2f}\"],\n",
        "     [\"Deep\", \"user and campaign id \\nembeddings\", \"none\", f\"{eval_dmodel_1_emb_train[1]:.2f}\", f\"{eval_dmodel_1_emb_val[1]:.2f}\", f\"{eval_dmodel_1_emb_test[1]}\"],\n",
        "     [\"Deep\", \"customer features 1&2,\\ncampaign features 1&2\", \"none\", f\"{eval_dmodel_2_num_train[1]:.2f}\", f\"{eval_dmodel_2_num_val[1]:.2f}\", f\"{eval_dmodel_2_num_test[1]:.2f}\"],\n",
        "     [\"Deep\", \"customer features 1&2,\\ncampaign features 1&2, \\nuser and campaign id \\nembeddings\", \"none\", f\"{eval_dmodel_3_num_emb_train[1]:.2f}\", f\"{eval_dmodel_3_num_emb_val[1]:.2f}\", f\"{eval_dmodel_3_num_emb_test[1]:.2f}\"],\n",
        "     [\"Deep\", \"customer features 1&2,\\ncampaign features 1&2, \\nhidden user and \\ncampaign features\", \"none\", f\"{eval_dmodel_4_hid_train[1]:.2f}\", f\"{eval_dmodel_4_hid_val[1]:.2f}\", f\"{eval_dmodel_4_hid_test[1]:.2f}\"],\n",
        "     [\"Wide & Deep\", \"customer features 1&2,\\ncampaign features 1&2\", \"none\", f\"{eval_wdmodel_train[1]:.2f}\", f\"{eval_wdmodel_val[1]:.2f}\", f\"{eval_wdmodel_test[1]:.2f}\"]]\n",
        "\n",
        "table = tabulate(l, headers=['Model', 'Deep Input', 'Wide Input', 'Train\\nAcc (%)', 'Val\\nAcc (%)', 'Tst\\nAcc (%)'], tablefmt='orgtbl')\n",
        "\n",
        "print(table)"
      ]
    }
  ]
}