# deep-and-wide-bandit
<br>
* Wide_and_Deep_Models folder - Add our best wide and deep models here <br>
* MAB_ToyExamples folder - MultiArm Bandits toy examples with epsilon-greedy, UCB, and Thompson sampling <br>
* DataExploration folder - Exploratory data analysis notebook <br><br>

