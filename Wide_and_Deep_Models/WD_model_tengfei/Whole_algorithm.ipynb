{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whole algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4msNAfHwsAK"
      },
      "source": [
        "## Summary of the progress:\r\n",
        "- Randomly choose 100000 data points from the data snippet. \r\n",
        "- Construct the contexts and the reward vectors.\r\n",
        "- Run the ContextualBandit: for every 1000 contexts seen, the following steps are done:\r\n",
        "    1. Run the algorithm(in this example it is LinUCB), store the 1000 seen rewards together with their contexts.\r\n",
        "    2. Then train the Wide and Deep model on these 1000 data points for 10 epoches.\r\n",
        "    3. Then update the algorithm's parameters (For LinUCB, they are A matrix and B vector) according to all the historical data points in order to keep the algorithm's knowledge by far.\r\n",
        "    4. Output the time spent on this 1000 data points. \r\n",
        "\r\n",
        "- finally plot the cumulative rewards, and print the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhKBSWlPeQjF"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "from collections import OrderedDict\r\n",
        "\r\n",
        "class Wide_Deep(nn.Module):\r\n",
        "    def __init__(self, wide_dim, deep_dim, action_dim, embeddings={}, deep_neurons=[32, 16], activation=nn.ReLU()):\r\n",
        "        \r\n",
        "        super(Wide_Deep, self).__init__()\r\n",
        "        self.wide_dim = wide_dim\r\n",
        "        self.deep_dim = deep_dim\r\n",
        "        self.context_dim = wide_dim + deep_dim\r\n",
        "        self.action_dim = action_dim\r\n",
        "        self.deep_neurons = deep_neurons\r\n",
        "\r\n",
        "        self.add_module('wide', nn.Module())\r\n",
        "        self.add_module('deep', nn.Module())\r\n",
        "\r\n",
        "        dims = {'wide':wide_dim, 'deep':deep_dim}\r\n",
        "        for name, child_module in self.named_children():\r\n",
        "            if name in embeddings.keys():\r\n",
        "                assert dims[name] >= len(embeddings[name]), \"Number of {} embedding features defined in embeddings should not more than {}_dim.\".format(name, name)\r\n",
        "                for embed in embeddings[name]:\r\n",
        "                    child_module.add_module(embed[0], nn.Embedding(embed[1], embed[2]))\r\n",
        "                    dims[name] += -1\r\n",
        "                    dims[name] += embed[2]  \r\n",
        "        self.dims = dims\r\n",
        "\r\n",
        "        if self.dims['deep'] == 0:\r\n",
        "            assert (self.dims['wide'] > 0), \"Both wide_dim and deep_dim are 0, at least one of them needs a positive value.\" \r\n",
        "            print(\"This is a wide-only model.\")\r\n",
        "            self.z_dim = self.dims['wide']\r\n",
        "        else:\r\n",
        "            if self.dims['wide'] == 0:\r\n",
        "                print(\"This is a deep-only model.\")\r\n",
        "            else:\r\n",
        "                print(\"This is a wide and deep model.\")\r\n",
        "            assert len(deep_neurons) > 0, \"deep_neurons must not be empty for the deep part.\"\r\n",
        "            deep_layers = OrderedDict()\r\n",
        "            layer_in = self.dims['deep']\r\n",
        "            for i, layer_out in enumerate(deep_neurons):\r\n",
        "                deep_layers['fc{}'.format(i)] = nn.Linear(layer_in, layer_out)\r\n",
        "                deep_layers['activ{}'.format(i)] = activation\r\n",
        "                layer_in = layer_out\r\n",
        "            self.deep.add_module('NN', nn.Sequential(deep_layers))\r\n",
        "            self.z_dim = self.dims['wide'] + deep_neurons[-1]\r\n",
        "\r\n",
        "        self.lastlayer = nn.Linear(self.z_dim, self.action_dim)\r\n",
        "\r\n",
        "    def get_z(self, x):\r\n",
        "        inputs = {'wide':x[:, :self.wide_dim], 'deep':x[:, self.wide_dim:]}\r\n",
        "        \r\n",
        "        after_embed = {}\r\n",
        "        for name, module in self.named_children():\r\n",
        "            if name not in ['wide', 'deep']:\r\n",
        "                break;\r\n",
        "            i = 0\r\n",
        "            for child in module.children():\r\n",
        "                if 'Embedding' in torch.typename(child):\r\n",
        "                    if name not in after_embed:\r\n",
        "                        after_embed[name] = child(inputs[name][:, i].long())\r\n",
        "                        i += 1\r\n",
        "                    else:\r\n",
        "                        after_embed[name] = torch.cat((after_embed[name], child(inputs[name][:, i].long())), dim=1)\r\n",
        "                        i += 1 \r\n",
        "            if name not in after_embed:\r\n",
        "                after_embed[name] = inputs[name]\r\n",
        "            else:\r\n",
        "                after_embed[name] = torch.cat((after_embed[name], inputs[name][:, i:]), dim=1)\r\n",
        "\r\n",
        "        if self.dims['deep'] == 0:\r\n",
        "            z = after_embed['wide']\r\n",
        "        elif self.dims['wide'] == 0:\r\n",
        "            z = self.deep.NN(after_embed['deep'])\r\n",
        "        else:\r\n",
        "            z = torch.cat((after_embed['wide'], self.deep.NN(after_embed['deep'])), dim=1)\r\n",
        "        \r\n",
        "        return z\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        z = self.get_z(x)\r\n",
        "        out = self.lastlayer(z)\r\n",
        "        return out\r\n",
        "                \r\n",
        "\r\n",
        "class ContextualBandit():\r\n",
        "    \r\n",
        "    def __init__(self, device, model, optimizer, loss_func, algorithm):\r\n",
        "        self.device = device\r\n",
        "        self.model = model.to(device)\r\n",
        "        self.context_dim = model.context_dim\r\n",
        "        self.z_dim = model.z_dim\r\n",
        "        self.action_dim = model.action_dim\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.loss_func = loss_func\r\n",
        "        self.algorithm = algorithm\r\n",
        "        self.reset()\r\n",
        "        \r\n",
        "    def reset(self):\r\n",
        "        self.dataset = []\r\n",
        "    \r\n",
        "    def observe_data(self, context_source):\r\n",
        "        x_t = np.array(context_source)\r\n",
        "        assert x_t.shape == (self.action_dim, self.context_dim)\r\n",
        "        return x_t \r\n",
        "    \r\n",
        "    def get_reward(self, reward_source, a_t):\r\n",
        "        r_t = float(reward_source[a_t])\r\n",
        "        return r_t\r\n",
        "\r\n",
        "    def run(self, context_source, reward_source):\r\n",
        "        x_t = self.observe_data(context_source) # x_t np.array size=(action_dim, context_dim)\r\n",
        "        x_t_tensor = torch.tensor(x_t).float().to(self.device)\r\n",
        "        z_t = self.model.get_z(x_t_tensor).detach().cpu().numpy() # z_t np.array size=(action_dim, context_dim)\r\n",
        "        a_t = self.algorithm.select_action(z_t) # a_t int range (0, action_dim)\r\n",
        "        r_t = self.get_reward(reward_source, a_t) # r_t float either from an online simulation or from a reward vertor(size=action_dim)  \r\n",
        "        data = (x_t[a_t], z_t[a_t], a_t, r_t)\r\n",
        "        self.dataset.append(data)\r\n",
        "        self.algorithm.update(data) # update selection strategy (parameters of algorithm)\r\n",
        "        \r\n",
        "        return a_t\r\n",
        "    \r\n",
        "    def train(self, start_index=0, batch_size=16, num_epoch=100):\r\n",
        "        # prepare dataset and dataloader for training\r\n",
        "        train_dataset = BanditDataset(self.dataset[start_index:])\r\n",
        "        train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "        # train num_epoch epoches\r\n",
        "        for i in range(num_epoch):\r\n",
        "            for data_batch in train_dataloader:\r\n",
        "                contexts, _, actions, rewards = data_batch\r\n",
        "                contexts = contexts.float().to(self.device)\r\n",
        "                actions = actions.long().to(self.device)\r\n",
        "                rewards = rewards.float().to(self.device)\r\n",
        "                outputs = model(contexts)\r\n",
        "                pred_rewards = outputs[range(outputs.shape[0]),actions]\r\n",
        "                loss = self.loss_func(pred_rewards, rewards)\r\n",
        "                self.optimizer.zero_grad()\r\n",
        "                loss.backward()\r\n",
        "                self.optimizer.step()                \r\n",
        "        # update algorithm's parameters after training\r\n",
        "        self.algorithm.reset()\r\n",
        "        for data in self.dataset:\r\n",
        "            x_t_a_t, _, a_t, r_t = data\r\n",
        "            x_t_a_t_tensor = torch.tensor(x_t_a_t).float().unsqueeze(0).to(self.device)\r\n",
        "            with torch.no_grad():\r\n",
        "                z_t_a_t = self.model.get_z(x_t_a_t_tensor).detach().cpu().numpy().reshape(-1)\r\n",
        "            self.algorithm.update((x_t_a_t, z_t_a_t, a_t, r_t))\r\n",
        "    \r\n",
        "class BanditDataset(torch.utils.data.Dataset):\r\n",
        "    \r\n",
        "    def __init__(self, raw_dataset):\r\n",
        "        self.dataset = raw_dataset\r\n",
        "        \r\n",
        "    def __getitem__(self, index):\r\n",
        "        context, z, action, reward = self.dataset[index]\r\n",
        "        return np.array(context), np.array(z), action, reward\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.dataset)\r\n",
        "    \r\n",
        "class LinUCB():\r\n",
        "    \r\n",
        "    def __init__(self, z_dim, action_dim, delta=0.05):\r\n",
        "        self.action_dim = action_dim\r\n",
        "        self.z_dim = z_dim\r\n",
        "        self.alpha = 1.0 + np.sqrt(np.log(2 / delta) / 2)\r\n",
        "        self.reset()\r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.A = [np.eye(self.z_dim) for i in range(self.action_dim)]\r\n",
        "        self.b = [np.zeros(self.z_dim) for i in range(self.action_dim)]\r\n",
        "    \r\n",
        "    def select_action(self, z_t):\r\n",
        "        theta = np.zeros((self.action_dim, self.z_dim))\r\n",
        "        ucb = np.zeros(self.action_dim)\r\n",
        "        for a in range(self.action_dim):\r\n",
        "            A_inv = np.linalg.inv(self.A[a])\r\n",
        "            theta[a] = np.dot(A_inv, self.b[a])\r\n",
        "            ucb[a] = np.dot(z_t[a], theta[a]) + self.alpha * np.sqrt(np.dot(np.dot(z_t[a], A_inv), z_t[a]))\r\n",
        "        \r\n",
        "        return np.argmax(ucb)\r\n",
        "    \r\n",
        "    def update(self, data):\r\n",
        "        _, z_t_a_t, a_t, r_t = data\r\n",
        "        assert z_t_a_t.shape == (self.z_dim, )\r\n",
        "        assert type(a_t) == np.int64\r\n",
        "        assert type(r_t) == float\r\n",
        "        self.A[a_t] += np.dot(z_t_a_t.reshape((self.z_dim, 1)), z_t_a_t.reshape((1, self.z_dim)))\r\n",
        "        self.b[a_t] += r_t * z_t_a_t\r\n",
        "    \r\n",
        "    \r\n",
        "class TS():\r\n",
        "    \r\n",
        "    def __init__(self, z_dim, action_dim, beta=0.0):\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def select_action(self, z_t):\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def update(self, data):\r\n",
        "        pass\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnww6BW4b7Yz",
        "outputId": "fedd1136-0503-4067-caba-4f942781c8e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WkoDW55iVEZf",
        "outputId": "2ccc1c47-f024-41d1-9f4b-f2a720a9cfc1"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "file_path = \"/content/drive/MyDrive/Fellowship.AI/P1_bandit/data_snippet.csv\"\r\n",
        "df = pd.read_csv(file_path)\r\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>riid</th>\n",
              "      <th>opened</th>\n",
              "      <th>rev_3dv2</th>\n",
              "      <th>unsub</th>\n",
              "      <th>campaign_type</th>\n",
              "      <th>retention_score</th>\n",
              "      <th>recency_score</th>\n",
              "      <th>frequency_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>242697842</td>\n",
              "      <td>1</td>\n",
              "      <td>75.00</td>\n",
              "      <td>0</td>\n",
              "      <td>Dedicated</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.637422</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>275469002</td>\n",
              "      <td>1</td>\n",
              "      <td>75.00</td>\n",
              "      <td>0</td>\n",
              "      <td>Dedicated</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4319542</td>\n",
              "      <td>1</td>\n",
              "      <td>19.98</td>\n",
              "      <td>0</td>\n",
              "      <td>Dedicated</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.084239</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>166170102</td>\n",
              "      <td>1</td>\n",
              "      <td>19.98</td>\n",
              "      <td>0</td>\n",
              "      <td>Dedicated</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6998482</td>\n",
              "      <td>1</td>\n",
              "      <td>150.00</td>\n",
              "      <td>0</td>\n",
              "      <td>Dedicated</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.845885</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        riid  opened  rev_3dv2  ...  retention_score recency_score  frequency_score\n",
              "0  242697842       1     75.00  ...        14.000000      1.637422               31\n",
              "1  275469002       1     75.00  ...         2.800000      0.000000                0\n",
              "2    4319542       1     19.98  ...         1.000000      0.084239                4\n",
              "3  166170102       1     19.98  ...         0.756757      0.010870                1\n",
              "4    6998482       1    150.00  ...        28.000000      1.845885               18\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY72wwmCZZOX",
        "outputId": "5d3109b8-176c-454d-d711-6f575c4ba850"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6240490"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q26m4nfHi0Y5"
      },
      "source": [
        "num_data = 100000\r\n",
        "indices = np.random.choice(len(df),size=num_data)\r\n",
        "df_subset = df.iloc[indices]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBmGyVObZC_F"
      },
      "source": [
        "vocab = {riid:i for i, riid in enumerate(df_subset.riid.unique())}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MohzyBqe17A",
        "outputId": "e3a2f521-a108-4fc0-9087-7e9ca908e6f0"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVyDfnE2ZTz_"
      },
      "source": [
        "user_ids = df_subset.riid.apply(lambda x:vocab[x])\r\n",
        "c_t = pd.get_dummies(df_subset.campaign_type)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeRlUSQ3Z8kh"
      },
      "source": [
        "datasource = pd.DataFrame()\r\n",
        "datasource['user_ids'] = user_ids"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwfGYpUKbMtf"
      },
      "source": [
        "datasource = pd.concat((datasource, c_t),axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH0a-jHqbaHv"
      },
      "source": [
        "datasource[[\"retention_score\",\t\"recency_score\",\t\"frequency_score\"]] = df_subset[[\"retention_score\",\t\"recency_score\",\t\"frequency_score\"]]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "MQrrwcfubqqk",
        "outputId": "80ebb0e5-4741-476c-b4a6-553de3c8f86d"
      },
      "source": [
        "datasource"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_ids</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Collection</th>\n",
              "      <th>Core</th>\n",
              "      <th>Dedicated</th>\n",
              "      <th>Innovation Spotlight</th>\n",
              "      <th>New Arrivals</th>\n",
              "      <th>Other</th>\n",
              "      <th>Product Spotlight</th>\n",
              "      <th>Replen</th>\n",
              "      <th>Tops</th>\n",
              "      <th>Trend</th>\n",
              "      <th>retention_score</th>\n",
              "      <th>recency_score</th>\n",
              "      <th>frequency_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2504873</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.286491</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4053721</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038640</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.077834</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887277</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.660132</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493858</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.900427</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176854</th>\n",
              "      <td>87732</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>28.0</td>\n",
              "      <td>3.608113</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2577873</th>\n",
              "      <td>87733</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.888393</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4755602</th>\n",
              "      <td>25052</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4.756988</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3063729</th>\n",
              "      <td>87734</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>7.209239</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974716</th>\n",
              "      <td>87735</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.283967</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_ids  Brand  ...  recency_score  frequency_score\n",
              "2504873         0      0  ...       2.286491               38\n",
              "4053721         1      0  ...       0.010870                1\n",
              "6038640         2      0  ...       4.077834               50\n",
              "887277          3      0  ...       1.660132               48\n",
              "1493858         4      1  ...       4.900427               78\n",
              "...           ...    ...  ...            ...              ...\n",
              "1176854     87732      0  ...       3.608113               67\n",
              "2577873     87733      0  ...       4.888393               14\n",
              "4755602     25052      0  ...       4.756988               42\n",
              "3063729     87734      0  ...       7.209239               69\n",
              "974716      87735      1  ...       1.283967               20\n",
              "\n",
              "[100000 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghLBFVtpbwHx"
      },
      "source": [
        "rewardsource = pd.DataFrame()\r\n",
        "rewardsource[\"reward_send\"] = df_subset.opened * 1.2 - 0.2 + (df_subset.rev_3dv2 > 0) + df_subset.rev_3dv2/75.0 - 5.0*df_subset.unsub\r\n",
        "rewardsource[\"reward_not_send\"] = -rewardsource[\"reward_send\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YsgwSNeFd3Qj",
        "outputId": "4dda036d-01c7-4d6c-b9f5-ed636e8862c7"
      },
      "source": [
        "rewardsource"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reward_send</th>\n",
              "      <th>reward_not_send</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2504873</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4053721</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6038640</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887277</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493858</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176854</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2577873</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4755602</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3063729</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974716</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         reward_send  reward_not_send\n",
              "2504873          1.0             -1.0\n",
              "4053721         -0.2              0.2\n",
              "6038640         -0.2              0.2\n",
              "887277           1.0             -1.0\n",
              "1493858          1.0             -1.0\n",
              "...              ...              ...\n",
              "1176854          1.0             -1.0\n",
              "2577873          1.0             -1.0\n",
              "4755602          1.0             -1.0\n",
              "3063729          1.0             -1.0\n",
              "974716           1.0             -1.0\n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swLZ47qcgFSr"
      },
      "source": [
        "opt_a = (rewardsource['reward_send'] < 0).astype(int)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgAqyRBUgdbE",
        "outputId": "9a7f2203-c7e6-4cae-9b1b-c98c5480c86c"
      },
      "source": [
        "opt_a"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2504873    0\n",
              "4053721    1\n",
              "6038640    1\n",
              "887277     0\n",
              "1493858    0\n",
              "          ..\n",
              "1176854    0\n",
              "2577873    0\n",
              "4755602    0\n",
              "3063729    0\n",
              "974716     0\n",
              "Name: reward_send, Length: 100000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6H_J1u-kuQy",
        "outputId": "c61bb58c-b083-4ae7-a0f6-f8d60c199011"
      },
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "print(\"training on device: \", device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ljb3WWMeUKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a26c0a-a871-4677-b2c4-cfca2bf53eca"
      },
      "source": [
        "wide_dim = 1\r\n",
        "deep_dim = 14\r\n",
        "action_dim = 2\r\n",
        "embeddings={'wide':[['user_id', len(vocab), 64]]}\r\n",
        "\r\n",
        "model = Wide_Deep(wide_dim, deep_dim, action_dim, embeddings=embeddings, deep_neurons=[128, 64]).to(device)\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005)\r\n",
        "loss_func = nn.MSELoss()\r\n",
        "algorithm = LinUCB(model.z_dim, model.action_dim, delta=0.05)\r\n",
        "CB = ContextualBandit(device, model, optimizer, loss_func, algorithm)\r\n",
        "\r\n",
        "train_batch_size = 64\r\n",
        "num_epoch = 10\r\n",
        "train_every = 1000\r\n",
        "contexts = datasource.values\r\n",
        "reward_vectors = rewardsource.values\r\n",
        "opt_actions = opt_a.values\r\n",
        "\r\n",
        "train_start_index = 0\r\n",
        "start_time = time.time()\r\n",
        "pred_actions = []\r\n",
        "s_time = start_time\r\n",
        "for t in range(num_data):\r\n",
        "    context_source = np.array([contexts[t] for i in range(model.action_dim)])\r\n",
        "    reward_source = reward_vectors[t]\r\n",
        "    pred_a = CB.run(context_source, reward_source)\r\n",
        "    pred_actions.append(pred_a)\r\n",
        "    if (t+1) % train_every == 0:\r\n",
        "        CB.train(start_index=train_start_index, batch_size=train_batch_size, num_epoch=num_epoch)\r\n",
        "        train_start_index = t + 1\r\n",
        "        print(\"number of data seen: {:>6} \\t time used for previous {} data: {:.3f} sec\".format(t+1, train_every, (time.time() - s_time)))\r\n",
        "        s_time = time.time()\r\n",
        "end_time = time.time()\r\n",
        "total_time = end_time - start_time\r\n",
        "print(\"Total time used: {} hrs {} min {} sec\".format(int(total_time//3600), int((total_time%3600)//60), total_time%60))\r\n",
        "\r\n",
        "cum_rewards_pred_action = []\r\n",
        "cum_rewards_opt_action = []\r\n",
        "p_i = 0\r\n",
        "o_i = 0\r\n",
        "for i in range(num_data):\r\n",
        "    p_i += reward_vectors[i][pred_actions[i]]\r\n",
        "    o_i += reward_vectors[i][opt_actions[i]]\r\n",
        "    cum_rewards_pred_action.append(p_i)\r\n",
        "    cum_rewards_opt_action.append(o_i)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a wide and deep model.\n",
            "number of data seen:   1000 \t time used for previous 1000 data: 3.404 sec\n",
            "number of data seen:   2000 \t time used for previous 1000 data: 3.921 sec\n",
            "number of data seen:   3000 \t time used for previous 1000 data: 4.218 sec\n",
            "number of data seen:   4000 \t time used for previous 1000 data: 5.017 sec\n",
            "number of data seen:   5000 \t time used for previous 1000 data: 5.215 sec\n",
            "number of data seen:   6000 \t time used for previous 1000 data: 5.761 sec\n",
            "number of data seen:   7000 \t time used for previous 1000 data: 6.297 sec\n",
            "number of data seen:   8000 \t time used for previous 1000 data: 6.793 sec\n",
            "number of data seen:   9000 \t time used for previous 1000 data: 7.563 sec\n",
            "number of data seen:  10000 \t time used for previous 1000 data: 7.833 sec\n",
            "number of data seen:  11000 \t time used for previous 1000 data: 8.445 sec\n",
            "number of data seen:  12000 \t time used for previous 1000 data: 8.567 sec\n",
            "number of data seen:  13000 \t time used for previous 1000 data: 9.021 sec\n",
            "number of data seen:  14000 \t time used for previous 1000 data: 9.872 sec\n",
            "number of data seen:  15000 \t time used for previous 1000 data: 10.247 sec\n",
            "number of data seen:  16000 \t time used for previous 1000 data: 10.952 sec\n",
            "number of data seen:  17000 \t time used for previous 1000 data: 11.222 sec\n",
            "number of data seen:  18000 \t time used for previous 1000 data: 12.071 sec\n",
            "number of data seen:  19000 \t time used for previous 1000 data: 11.981 sec\n",
            "number of data seen:  20000 \t time used for previous 1000 data: 13.005 sec\n",
            "number of data seen:  21000 \t time used for previous 1000 data: 13.006 sec\n",
            "number of data seen:  22000 \t time used for previous 1000 data: 13.902 sec\n",
            "number of data seen:  23000 \t time used for previous 1000 data: 14.574 sec\n",
            "number of data seen:  24000 \t time used for previous 1000 data: 14.332 sec\n",
            "number of data seen:  25000 \t time used for previous 1000 data: 14.714 sec\n",
            "number of data seen:  26000 \t time used for previous 1000 data: 15.526 sec\n",
            "number of data seen:  27000 \t time used for previous 1000 data: 16.456 sec\n",
            "number of data seen:  28000 \t time used for previous 1000 data: 16.199 sec\n",
            "number of data seen:  29000 \t time used for previous 1000 data: 16.572 sec\n",
            "number of data seen:  30000 \t time used for previous 1000 data: 17.773 sec\n",
            "number of data seen:  31000 \t time used for previous 1000 data: 18.411 sec\n",
            "number of data seen:  32000 \t time used for previous 1000 data: 19.352 sec\n",
            "number of data seen:  33000 \t time used for previous 1000 data: 18.929 sec\n",
            "number of data seen:  34000 \t time used for previous 1000 data: 19.466 sec\n",
            "number of data seen:  35000 \t time used for previous 1000 data: 20.002 sec\n",
            "number of data seen:  36000 \t time used for previous 1000 data: 20.645 sec\n",
            "number of data seen:  37000 \t time used for previous 1000 data: 21.244 sec\n",
            "number of data seen:  38000 \t time used for previous 1000 data: 21.549 sec\n",
            "number of data seen:  39000 \t time used for previous 1000 data: 22.487 sec\n",
            "number of data seen:  40000 \t time used for previous 1000 data: 23.113 sec\n",
            "number of data seen:  41000 \t time used for previous 1000 data: 22.121 sec\n",
            "number of data seen:  42000 \t time used for previous 1000 data: 23.608 sec\n",
            "number of data seen:  43000 \t time used for previous 1000 data: 24.619 sec\n",
            "number of data seen:  44000 \t time used for previous 1000 data: 24.790 sec\n",
            "number of data seen:  45000 \t time used for previous 1000 data: 25.074 sec\n",
            "number of data seen:  46000 \t time used for previous 1000 data: 26.500 sec\n",
            "number of data seen:  47000 \t time used for previous 1000 data: 26.158 sec\n",
            "number of data seen:  48000 \t time used for previous 1000 data: 26.149 sec\n",
            "number of data seen:  49000 \t time used for previous 1000 data: 26.955 sec\n",
            "number of data seen:  50000 \t time used for previous 1000 data: 27.571 sec\n",
            "number of data seen:  51000 \t time used for previous 1000 data: 28.041 sec\n",
            "number of data seen:  52000 \t time used for previous 1000 data: 29.534 sec\n",
            "number of data seen:  53000 \t time used for previous 1000 data: 28.554 sec\n",
            "number of data seen:  54000 \t time used for previous 1000 data: 28.976 sec\n",
            "number of data seen:  55000 \t time used for previous 1000 data: 30.048 sec\n",
            "number of data seen:  56000 \t time used for previous 1000 data: 30.661 sec\n",
            "number of data seen:  57000 \t time used for previous 1000 data: 31.204 sec\n",
            "number of data seen:  58000 \t time used for previous 1000 data: 31.627 sec\n",
            "number of data seen:  59000 \t time used for previous 1000 data: 31.883 sec\n",
            "number of data seen:  60000 \t time used for previous 1000 data: 32.901 sec\n",
            "number of data seen:  61000 \t time used for previous 1000 data: 32.772 sec\n",
            "number of data seen:  62000 \t time used for previous 1000 data: 33.105 sec\n",
            "number of data seen:  63000 \t time used for previous 1000 data: 34.207 sec\n",
            "number of data seen:  64000 \t time used for previous 1000 data: 34.591 sec\n",
            "number of data seen:  65000 \t time used for previous 1000 data: 35.249 sec\n",
            "number of data seen:  66000 \t time used for previous 1000 data: 35.285 sec\n",
            "number of data seen:  67000 \t time used for previous 1000 data: 36.806 sec\n",
            "number of data seen:  68000 \t time used for previous 1000 data: 35.852 sec\n",
            "number of data seen:  69000 \t time used for previous 1000 data: 36.443 sec\n",
            "number of data seen:  70000 \t time used for previous 1000 data: 37.744 sec\n",
            "number of data seen:  71000 \t time used for previous 1000 data: 37.655 sec\n",
            "number of data seen:  72000 \t time used for previous 1000 data: 37.639 sec\n",
            "number of data seen:  73000 \t time used for previous 1000 data: 38.775 sec\n",
            "number of data seen:  74000 \t time used for previous 1000 data: 40.148 sec\n",
            "number of data seen:  75000 \t time used for previous 1000 data: 40.619 sec\n",
            "number of data seen:  76000 \t time used for previous 1000 data: 40.370 sec\n",
            "number of data seen:  77000 \t time used for previous 1000 data: 40.413 sec\n",
            "number of data seen:  78000 \t time used for previous 1000 data: 41.152 sec\n",
            "number of data seen:  79000 \t time used for previous 1000 data: 41.895 sec\n",
            "number of data seen:  80000 \t time used for previous 1000 data: 42.501 sec\n",
            "number of data seen:  81000 \t time used for previous 1000 data: 42.909 sec\n",
            "number of data seen:  82000 \t time used for previous 1000 data: 43.376 sec\n",
            "number of data seen:  83000 \t time used for previous 1000 data: 44.035 sec\n",
            "number of data seen:  84000 \t time used for previous 1000 data: 43.429 sec\n",
            "number of data seen:  85000 \t time used for previous 1000 data: 44.761 sec\n",
            "number of data seen:  86000 \t time used for previous 1000 data: 45.409 sec\n",
            "number of data seen:  87000 \t time used for previous 1000 data: 46.572 sec\n",
            "number of data seen:  88000 \t time used for previous 1000 data: 46.262 sec\n",
            "number of data seen:  89000 \t time used for previous 1000 data: 46.968 sec\n",
            "number of data seen:  90000 \t time used for previous 1000 data: 48.080 sec\n",
            "number of data seen:  91000 \t time used for previous 1000 data: 47.835 sec\n",
            "number of data seen:  92000 \t time used for previous 1000 data: 49.500 sec\n",
            "number of data seen:  93000 \t time used for previous 1000 data: 48.639 sec\n",
            "number of data seen:  94000 \t time used for previous 1000 data: 48.844 sec\n",
            "number of data seen:  95000 \t time used for previous 1000 data: 49.390 sec\n",
            "number of data seen:  96000 \t time used for previous 1000 data: 49.864 sec\n",
            "number of data seen:  97000 \t time used for previous 1000 data: 51.076 sec\n",
            "number of data seen:  98000 \t time used for previous 1000 data: 52.350 sec\n",
            "number of data seen:  99000 \t time used for previous 1000 data: 52.243 sec\n",
            "number of data seen: 100000 \t time used for previous 1000 data: 52.652 sec\n",
            "Total time used: -1 hrs 13 min 35.9398775100708 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONE-QJH4qiuz",
        "outputId": "3803062c-18a1-4857-802a-afc8bc766f0c"
      },
      "source": [
        "total_time = end_time - start_time\r\n",
        "print(\"Total time used: {} hrs {} min {} sec\".format(int(total_time//3600), int((total_time%3600)//60), total_time%60))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time used: 0 hrs 46 min 24.0601224899292 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15SjzxXHeV0q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "15adeae5-fc5c-4104-c0b4-007d5e77f1ed"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(cum_rewards_pred_action, label = 'cum_rewards_pred_action')\r\n",
        "plt.plot(cum_rewards_opt_action, label = 'cum_rewards_opt_action')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('num data')\r\n",
        "_ = plt.ylabel('cum rewards')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85a0LauFeXQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714d05ee-4409-406d-b8e7-ecdb3299abe3"
      },
      "source": [
        "np.sum(pred_actions == opt_actions)/num_data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.70715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NQ2GhvBqoSQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}