{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "testing full dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSrMHFSIsh8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec1d718-0422-40ba-de69-4c08cf2c261a"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import json \r\n",
        "import os\r\n",
        "import time\r\n",
        "from sklearn import model_selection\r\n",
        "import importlib.util\r\n",
        "spec = importlib.util.spec_from_file_location(\"Wide_and_Deep_model\", \"/content/drive/MyDrive/Colab Notebooks/Wide_and_Deep_model.py\")\r\n",
        "Wide_and_Deep_model = importlib.util.module_from_spec(spec)\r\n",
        "spec.loader.exec_module(Wide_and_Deep_model)\r\n",
        "Wide_Deep = Wide_and_Deep_model.Wide_Deep\r\n",
        "\r\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "print(\"train on device: \", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train on device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1INasCtopX7",
        "outputId": "269349e3-2102-4704-fcb3-ea235b85a6b7"
      },
      "source": [
        "riid_all = pd.DataFrame()\r\n",
        "\r\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Fellowship.AI/P1_bandit/dataset/datas'):\r\n",
        "    for filename in filenames:\r\n",
        "        print(filename)\r\n",
        "        data_path = os.path.join(dirname, filename)\r\n",
        "        riid = pd.read_csv(data_path, usecols=['riid'])\r\n",
        "        riid_all = pd.concat((riid_all, riid),axis=0)\r\n",
        "\r\n",
        "vocab = {r:i for i, r in enumerate(riid_all.riid.unique())}\r\n",
        "print(\"number of total data points:\", len(riid_all))\r\n",
        "print(\"number of unique users:\", len(vocab))\r\n",
        "del riid, riid_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sends_2020_wk01.csv\n",
            "sends_2020_wk04.csv\n",
            "sends_2020_wk02.csv\n",
            "sends_2020_wk03.csv\n",
            "sends_2020_wk00.csv\n",
            "sends_2020_wk05.csv\n",
            "sends_2020_wk07.csv\n",
            "sends_2020_wk08.csv\n",
            "sends_2020_wk06.csv\n",
            "sends_2020_wk09.csv\n",
            "sends_2020_wk12.csv\n",
            "sends_2020_wk10.csv\n",
            "sends_2020_wk11.csv\n",
            "sends_2020_wk16.csv\n",
            "sends_2020_wk14.csv\n",
            "sends_2020_wk13.csv\n",
            "sends_2020_wk17.csv\n",
            "sends_2020_wk15.csv\n",
            "sends_2020_wk19.csv\n",
            "sends_2020_wk21.csv\n",
            "sends_2020_wk18.csv\n",
            "sends_2020_wk20.csv\n",
            "sends_2020_wk22.csv\n",
            "sends_2020_wk23.csv\n",
            "sends_2020_wk24.csv\n",
            "sends_2020_wk25.csv\n",
            "sends_2019_wk27.csv\n",
            "sends_2019_wk29.csv\n",
            "sends_2019_wk28.csv\n",
            "sends_2019_wk26.csv\n",
            "sends_2019_wk33.csv\n",
            "sends_2019_wk32.csv\n",
            "sends_2019_wk30.csv\n",
            "sends_2019_wk31.csv\n",
            "sends_2019_wk34.csv\n",
            "sends_2019_wk36.csv\n",
            "sends_2019_wk37.csv\n",
            "sends_2019_wk35.csv\n",
            "sends_2019_wk41.csv\n",
            "sends_2019_wk38.csv\n",
            "sends_2019_wk40.csv\n",
            "sends_2019_wk39.csv\n",
            "sends_2019_wk43.csv\n",
            "sends_2019_wk44.csv\n",
            "sends_2019_wk42.csv\n",
            "sends_2019_wk45.csv\n",
            "sends_2019_wk46.csv\n",
            "sends_2019_wk50.csv\n",
            "sends_2019_wk49.csv\n",
            "sends_2019_wk48.csv\n",
            "sends_2019_wk51.csv\n",
            "sends_2019_wk52.csv\n",
            "sends_2019_wk47.csv\n",
            "number of total data points: 70409094\n",
            "number of unique users: 1717160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmU27PrMnryL"
      },
      "source": [
        "context_columns = ['sends_since_last_open',\r\n",
        "                   'retention_score', \r\n",
        "                   'recency_score',\r\n",
        "                   'frequency_score',\r\n",
        "                   'is_one_for_free', \r\n",
        "                   'is_exclusive', \r\n",
        "                   'free_shipping',\r\n",
        "                   'has_urgency', \r\n",
        "                   'sl_contains_price', \r\n",
        "                   'is_discount_mentioned',\r\n",
        "                   'campaign_Brand', \r\n",
        "                   'campaign_Core', \r\n",
        "                   'campaign_Dedicated', \r\n",
        "                   'campaign_InnovationSpotlight',\r\n",
        "                   'campaign_NewArrivals', \r\n",
        "                   'campaign_ProductSpotlight', \r\n",
        "                   'campaign_Replen',\r\n",
        "                   'campaign_Tops', \r\n",
        "                   'campaign_Trend', \r\n",
        "                   'campaign_Other']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLYpxyhrl16R"
      },
      "source": [
        "# A custumized class of torch dataset for the training\r\n",
        "class Mydataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, df_data):\r\n",
        "        self.data = np.array(df_data)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        context = self.data[index][:-1]\r\n",
        "        optimal_action = self.data[index][-1]\r\n",
        "        return context, optimal_action\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2KSJ2Oirwwd"
      },
      "source": [
        "def train_week(device, model, optimizer, loss_func, dataloader, num_epoch=1):\r\n",
        "    for i in range(num_epoch):\r\n",
        "        model.train()\r\n",
        "        corrects = 0.0\r\n",
        "        train_loss = 0.0\r\n",
        "        for c_train, opt_a_train in dataloader:\r\n",
        "            c_train = c_train.float().to(device)\r\n",
        "            opt_a_train = opt_a_train.long().to(device)\r\n",
        "\r\n",
        "            pred_out_train = model(c_train)\r\n",
        "\r\n",
        "            loss = loss_func(pred_out_train, opt_a_train)\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            pred_a_train = torch.argmax(pred_out_train, dim=1)\r\n",
        "            corrects += torch.sum(pred_a_train==opt_a_train).item()\r\n",
        "            train_loss += loss.item() * c_train.shape[0]\r\n",
        "    return corrects, train_loss\r\n",
        "\r\n",
        "def valid(device, model, loss_func, dataloader):\r\n",
        "    model.eval()\r\n",
        "    corrects = 0.0\r\n",
        "    losses = 0.0\r\n",
        "    for c, opt_a in dataloader:\r\n",
        "        c = c.float().to(device)\r\n",
        "        opt_a = opt_a.long().to(device)\r\n",
        "        pred_out = model(c)\r\n",
        "        loss = loss_func(pred_out, opt_a)\r\n",
        "        pred_a = torch.argmax(pred_out, dim=1)\r\n",
        "        corrects += torch.sum(pred_a==opt_a).item()\r\n",
        "        losses += loss.item() * c.shape[0]\r\n",
        "    accuracy = corrects/len(dataloader.dataset)\r\n",
        "    average_loss = losses/len(dataloader.dataset)\r\n",
        "    return accuracy, average_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzaUzctxDDiJ",
        "outputId": "3eac3c27-9354-41c9-9786-f345c848eb70"
      },
      "source": [
        "# create a deep-only model and train it\r\n",
        "wide_dim = 1\r\n",
        "deep_dim = 20\r\n",
        "action_dim = 2\r\n",
        "embeddings = {'wide':[['user_id', len(vocab), 64]]}\r\n",
        "deep_neurons = [128, 64]\r\n",
        "model = Wide_Deep(wide_dim, deep_dim, action_dim, embeddings=embeddings, deep_neurons=deep_neurons).to(device)\r\n",
        "loss_func = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a wide and deep model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9enAGbwOkOeK",
        "outputId": "48f3bc64-7866-4afc-8d17-db8ab38561a2"
      },
      "source": [
        "num_epoch = 3\r\n",
        "for i in range(num_epoch):\r\n",
        "    start_time = time.time()\r\n",
        "    if i==0:\r\n",
        "        df_valid = pd.DataFrame()\r\n",
        "    total_corrects = 0.0\r\n",
        "    total_loss = 0.0\r\n",
        "    total_len = 0\r\n",
        "    for dirname, _, filenames in os.walk('/content/drive/MyDrive/Fellowship.AI/P1_bandit/dataset/datas'):\r\n",
        "        for filename in filenames:\r\n",
        "            print(filename)\r\n",
        "            data_path = os.path.join(dirname, filename)\r\n",
        "            df_week = pd.read_csv(data_path, usecols=['riid']+context_columns+['optimal_action'])\r\n",
        "            df_week['riid'] = df_week.riid.apply(lambda x:vocab[x])\r\n",
        "            df_week_train, df_week_valid = model_selection.train_test_split(df_week, train_size=0.95, random_state=33)\r\n",
        "            if i==0:\r\n",
        "                df_valid = pd.concat((df_valid, df_week_valid), axis=0)\r\n",
        "            batch_size = 8192\r\n",
        "            dataset = Mydataset(df_week_train)\r\n",
        "            dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\r\n",
        "            corrects_week, loss_week = train_week(device, model, optimizer, loss_func, dataloader)\r\n",
        "            total_corrects += corrects_week\r\n",
        "            total_loss += loss_week\r\n",
        "            total_len += len(dataset)\r\n",
        "\r\n",
        "    train_accuracy = total_corrects/total_len\r\n",
        "    train_average_loss = total_loss/total_len\r\n",
        "    print(\"Epoch:{:>4}\\t Training Loss: {:6.3f}\\t Training Accuracy: {:.3f}\\t time used: {:.3f} sec\".format(i+1, train_average_loss, train_accuracy, time.time()-start_time))\r\n",
        "    start_time = time.time()\r\n",
        "    dataset = Mydataset(df_valid)\r\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\r\n",
        "    valid_accuracy, valid_average_loss = valid(device, model, loss_func, dataloader)\r\n",
        "    print(\"Epoch:{:>4}\\t Valid Loss: {:6.3f}\\t Valid Accuracy: {:.3f}\\t time used: {:.3f} sec\".format(i+1, valid_average_loss, valid_accuracy, time.time()-start_time))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sends_2020_wk01.csv\n",
            "sends_2020_wk04.csv\n",
            "sends_2020_wk02.csv\n",
            "sends_2020_wk03.csv\n",
            "sends_2020_wk00.csv\n",
            "sends_2020_wk05.csv\n",
            "sends_2020_wk07.csv\n",
            "sends_2020_wk08.csv\n",
            "sends_2020_wk06.csv\n",
            "sends_2020_wk09.csv\n",
            "sends_2020_wk12.csv\n",
            "sends_2020_wk10.csv\n",
            "sends_2020_wk11.csv\n",
            "sends_2020_wk16.csv\n",
            "sends_2020_wk14.csv\n",
            "sends_2020_wk13.csv\n",
            "sends_2020_wk17.csv\n",
            "sends_2020_wk15.csv\n",
            "sends_2020_wk19.csv\n",
            "sends_2020_wk21.csv\n",
            "sends_2020_wk18.csv\n",
            "sends_2020_wk20.csv\n",
            "sends_2020_wk22.csv\n",
            "sends_2020_wk23.csv\n",
            "sends_2020_wk24.csv\n",
            "sends_2020_wk25.csv\n",
            "sends_2019_wk27.csv\n",
            "sends_2019_wk29.csv\n",
            "sends_2019_wk28.csv\n",
            "sends_2019_wk26.csv\n",
            "sends_2019_wk33.csv\n",
            "sends_2019_wk32.csv\n",
            "sends_2019_wk30.csv\n",
            "sends_2019_wk31.csv\n",
            "sends_2019_wk34.csv\n",
            "sends_2019_wk36.csv\n",
            "sends_2019_wk37.csv\n",
            "sends_2019_wk35.csv\n",
            "sends_2019_wk41.csv\n",
            "sends_2019_wk38.csv\n",
            "sends_2019_wk40.csv\n",
            "sends_2019_wk39.csv\n",
            "sends_2019_wk43.csv\n",
            "sends_2019_wk44.csv\n",
            "sends_2019_wk42.csv\n",
            "sends_2019_wk45.csv\n",
            "sends_2019_wk46.csv\n",
            "sends_2019_wk50.csv\n",
            "sends_2019_wk49.csv\n",
            "sends_2019_wk48.csv\n",
            "sends_2019_wk51.csv\n",
            "sends_2019_wk52.csv\n",
            "sends_2019_wk47.csv\n",
            "Epoch:   1\t Training Loss:  0.340\t Training Accuracy: 0.861\t time used: 1182.950 sec\n",
            "Epoch:   1\t Valid Loss:  0.343\t Valid Accuracy: 0.862\t time used: 29.238 sec\n",
            "sends_2020_wk01.csv\n",
            "sends_2020_wk04.csv\n",
            "sends_2020_wk02.csv\n",
            "sends_2020_wk03.csv\n",
            "sends_2020_wk00.csv\n",
            "sends_2020_wk05.csv\n",
            "sends_2020_wk07.csv\n",
            "sends_2020_wk08.csv\n",
            "sends_2020_wk06.csv\n",
            "sends_2020_wk09.csv\n",
            "sends_2020_wk12.csv\n",
            "sends_2020_wk10.csv\n",
            "sends_2020_wk11.csv\n",
            "sends_2020_wk16.csv\n",
            "sends_2020_wk14.csv\n",
            "sends_2020_wk13.csv\n",
            "sends_2020_wk17.csv\n",
            "sends_2020_wk15.csv\n",
            "sends_2020_wk19.csv\n",
            "sends_2020_wk21.csv\n",
            "sends_2020_wk18.csv\n",
            "sends_2020_wk20.csv\n",
            "sends_2020_wk22.csv\n",
            "sends_2020_wk23.csv\n",
            "sends_2020_wk24.csv\n",
            "sends_2020_wk25.csv\n",
            "sends_2019_wk27.csv\n",
            "sends_2019_wk29.csv\n",
            "sends_2019_wk28.csv\n",
            "sends_2019_wk26.csv\n",
            "sends_2019_wk33.csv\n",
            "sends_2019_wk32.csv\n",
            "sends_2019_wk30.csv\n",
            "sends_2019_wk31.csv\n",
            "sends_2019_wk34.csv\n",
            "sends_2019_wk36.csv\n",
            "sends_2019_wk37.csv\n",
            "sends_2019_wk35.csv\n",
            "sends_2019_wk41.csv\n",
            "sends_2019_wk38.csv\n",
            "sends_2019_wk40.csv\n",
            "sends_2019_wk39.csv\n",
            "sends_2019_wk43.csv\n",
            "sends_2019_wk44.csv\n",
            "sends_2019_wk42.csv\n",
            "sends_2019_wk45.csv\n",
            "sends_2019_wk46.csv\n",
            "sends_2019_wk50.csv\n",
            "sends_2019_wk49.csv\n",
            "sends_2019_wk48.csv\n",
            "sends_2019_wk51.csv\n",
            "sends_2019_wk52.csv\n",
            "sends_2019_wk47.csv\n",
            "Epoch:   2\t Training Loss:  0.323\t Training Accuracy: 0.868\t time used: 1165.726 sec\n",
            "Epoch:   2\t Valid Loss:  0.333\t Valid Accuracy: 0.866\t time used: 27.603 sec\n",
            "sends_2020_wk01.csv\n",
            "sends_2020_wk04.csv\n",
            "sends_2020_wk02.csv\n",
            "sends_2020_wk03.csv\n",
            "sends_2020_wk00.csv\n",
            "sends_2020_wk05.csv\n",
            "sends_2020_wk07.csv\n",
            "sends_2020_wk08.csv\n",
            "sends_2020_wk06.csv\n",
            "sends_2020_wk09.csv\n",
            "sends_2020_wk12.csv\n",
            "sends_2020_wk10.csv\n",
            "sends_2020_wk11.csv\n",
            "sends_2020_wk16.csv\n",
            "sends_2020_wk14.csv\n",
            "sends_2020_wk13.csv\n",
            "sends_2020_wk17.csv\n",
            "sends_2020_wk15.csv\n",
            "sends_2020_wk19.csv\n",
            "sends_2020_wk21.csv\n",
            "sends_2020_wk18.csv\n",
            "sends_2020_wk20.csv\n",
            "sends_2020_wk22.csv\n",
            "sends_2020_wk23.csv\n",
            "sends_2020_wk24.csv\n",
            "sends_2020_wk25.csv\n",
            "sends_2019_wk27.csv\n",
            "sends_2019_wk29.csv\n",
            "sends_2019_wk28.csv\n",
            "sends_2019_wk26.csv\n",
            "sends_2019_wk33.csv\n",
            "sends_2019_wk32.csv\n",
            "sends_2019_wk30.csv\n",
            "sends_2019_wk31.csv\n",
            "sends_2019_wk34.csv\n",
            "sends_2019_wk36.csv\n",
            "sends_2019_wk37.csv\n",
            "sends_2019_wk35.csv\n",
            "sends_2019_wk41.csv\n",
            "sends_2019_wk38.csv\n",
            "sends_2019_wk40.csv\n",
            "sends_2019_wk39.csv\n",
            "sends_2019_wk43.csv\n",
            "sends_2019_wk44.csv\n",
            "sends_2019_wk42.csv\n",
            "sends_2019_wk45.csv\n",
            "sends_2019_wk46.csv\n",
            "sends_2019_wk50.csv\n",
            "sends_2019_wk49.csv\n",
            "sends_2019_wk48.csv\n",
            "sends_2019_wk51.csv\n",
            "sends_2019_wk52.csv\n",
            "sends_2019_wk47.csv\n",
            "Epoch:   3\t Training Loss:  0.318\t Training Accuracy: 0.870\t time used: 1163.544 sec\n",
            "Epoch:   3\t Valid Loss:  0.332\t Valid Accuracy: 0.866\t time used: 27.956 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}